{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 归一化预处理\n",
    "class Normalizer:\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        初始化类，接收一个DataFrame作为输入。\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.normalized_data = None\n",
    "        self.scaler_params = None\n",
    "\n",
    "    def get_normalization_params(self):\n",
    "        \"\"\"\n",
    "        获取归一化参数（基于MinMaxScaler）。\n",
    "        \"\"\"\n",
    "        # 拟合数据以获取归一化参数\n",
    "        self.scaler.fit(self.dataframe)\n",
    "        \n",
    "        # 保存归一化参数\n",
    "        self.scaler_params = {\n",
    "            'data_min': self.scaler.data_min_,\n",
    "            'data_max': self.scaler.data_max_\n",
    "        }\n",
    "        return self.scaler_params\n",
    "\n",
    "    def preprocess(self, otherdata=None):\n",
    "        \"\"\"\n",
    "        对数据进行归一化处理。\n",
    "        使用类中的归一化参数，如果参数为空则抛出提示。\n",
    "\n",
    "        参数:\n",
    "        - otherdata: 可选参数，指定需要归一化的数据。如果未提供，则默认使用类中的dataframe。\n",
    "        \"\"\"\n",
    "        if self.scaler_params is None:\n",
    "            raise ValueError(\"归一化参数为空！请先调用 `get_normalization_params` 方法获取归一化参数。\")\n",
    "        \n",
    "        # 如果未提供otherdata，则使用类中的dataframe\n",
    "        if otherdata is None:\n",
    "            otherdata = self.dataframe\n",
    "        \n",
    "        # 使用类中的归一化参数进行归一化\n",
    "        data_min = self.scaler_params['data_min']\n",
    "        data_max = self.scaler_params['data_max']\n",
    "        normalized_data = (otherdata - data_min) / (data_max - data_min)\n",
    "        \n",
    "        # 将归一化后的数据转换回DataFrame\n",
    "        normalized_df = pd.DataFrame(normalized_data, columns=otherdata.columns)\n",
    "        return normalized_df\n",
    "\n",
    "# 从 CSV 文件中读取数据并转换为 DataFrame\n",
    "df_drop = pd.read_csv('df_drop.csv')\n",
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###自定义运行逻辑回归的类###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class LogisticRegressionExperiment:\n",
    "    def __init__(self, df, target_col, continuous_cols, preprocess_method='normalize', use_smote=False, random_state=68):\n",
    "        \"\"\"\n",
    "        初始化实验类\n",
    "        :param df: 数据集\n",
    "        :param target_col: 目标列名\n",
    "        :param continuous_cols: 连续变量列名列表\n",
    "        :param preprocess_method: 预处理方法，可选 'none', 'normalize', 'log_normalize'\n",
    "        :param use_smote: 是否使用 SMOTE 过采样\n",
    "        :param random_state: 随机种子\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.target_col = target_col\n",
    "        self.continuous_cols = continuous_cols\n",
    "        self.preprocess_method = preprocess_method\n",
    "        self.use_smote = use_smote\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def preprocess_data(self, train_df, test_df):\n",
    "        \"\"\"\n",
    "        数据预处理方法\n",
    "        :param train_df: 训练集\n",
    "        :param test_df: 测试集\n",
    "        :return: 处理后的训练集和测试集\n",
    "        \"\"\"\n",
    "        # 创建副本以避免操作视图\n",
    "        train_df = train_df.copy()\n",
    "        test_df = test_df.copy()\n",
    "\n",
    "        if self.preprocess_method == 'normalize':\n",
    "            scaler = MinMaxScaler()\n",
    "            train_df.loc[:, self.continuous_cols] = scaler.fit_transform(train_df.loc[:, self.continuous_cols])\n",
    "            test_df.loc[:, self.continuous_cols] = scaler.transform(test_df.loc[:, self.continuous_cols])\n",
    "        elif self.preprocess_method == 'log_normalize':\n",
    "            # 对训练集和测试集取对数\n",
    "            train_log = train_df.loc[:, self.continuous_cols].apply(lambda x: np.log(x + 1))  # 加 1 避免 log(0)\n",
    "            test_log = test_df.loc[:, self.continuous_cols].apply(lambda x: np.log(x + 1))  # 加 1 避免 log(0)\n",
    "\n",
    "            # 归一化\n",
    "            scaler = MinMaxScaler()\n",
    "            train_df.loc[:, self.continuous_cols] = scaler.fit_transform(train_log)\n",
    "            test_df.loc[:, self.continuous_cols] = scaler.transform(test_log)\n",
    "        # 如果 preprocess_method 是 'none'，则不进行任何处理\n",
    "        return train_df, test_df\n",
    "\n",
    "    def run_experiment(self):\n",
    "        \"\"\"\n",
    "        运行逻辑回归实验\n",
    "        \"\"\"\n",
    "        # 打印当前实验配置\n",
    "        print(f\"正在运行实验 - 预处理方法: {self.preprocess_method}, 使用 SMOTE: {self.use_smote}\")\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=self.random_state)\n",
    "        results = []\n",
    "        iterations = []\n",
    "\n",
    "        for train_index, test_index in kf.split(self.df):\n",
    "            train_df, test_df = self.df.iloc[train_index, :], self.df.iloc[test_index, :]\n",
    "            train_df, test_df = self.preprocess_data(train_df, test_df)\n",
    "\n",
    "            X_train = train_df.drop(self.target_col, axis=1)\n",
    "            y_train = train_df[self.target_col]\n",
    "            X_test = test_df.drop(self.target_col, axis=1)\n",
    "            y_test = test_df[self.target_col]\n",
    "\n",
    "            # 根据 use_smote 参数决定是否使用 SMOTE\n",
    "            if self.use_smote:\n",
    "                smote = SMOTE(random_state=self.random_state)\n",
    "                X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "            else:\n",
    "                X_train_resampled, y_train_resampled = X_train, y_train\n",
    "\n",
    "            # 训练逻辑回归模型\n",
    "            model = LogisticRegression(max_iter=2000)\n",
    "            model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "            # 记录迭代次数\n",
    "            iterations.append(model.n_iter_[0])\n",
    "\n",
    "            # 在测试集上评估模型\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # 保存评估结果\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            results.append({\n",
    "                'precision': report['weighted avg']['precision'],\n",
    "                'recall': report['weighted avg']['recall'],\n",
    "                'f1_score': report['weighted avg']['f1-score'],\n",
    "                'auc': auc,\n",
    "                'accuracy': accuracy\n",
    "            })\n",
    "\n",
    "        # 输出平均评估结果\n",
    "        avg_precision = np.mean([result['precision'] for result in results])\n",
    "        avg_recall = np.mean([result['recall'] for result in results])\n",
    "        avg_f1_score = np.mean([result['f1_score'] for result in results])\n",
    "        avg_auc = np.mean([result['auc'] for result in results])\n",
    "        avg_accuracy = np.mean([result['accuracy'] for result in results])\n",
    "        avg_iterations = np.mean(iterations)\n",
    "\n",
    "        print(f\"平均 Precision: {avg_precision:.4f}\")\n",
    "        print(f\"平均 Recall: {avg_recall:.4f}\")\n",
    "        print(f\"平均 F1 Score: {avg_f1_score:.4f}\")\n",
    "        print(f\"平均 AUC: {avg_auc:.4f}\")\n",
    "        print(f\"平均 Accuracy: {avg_accuracy:.4f}\")\n",
    "        print(f\"平均迭代次数: {avg_iterations:.1f}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在运行实验 - 预处理方法: none, 使用 SMOTE: False\n",
      "平均 Precision: 0.8754\n",
      "平均 Recall: 0.8836\n",
      "平均 F1 Score: 0.8676\n",
      "平均 AUC: 0.8254\n",
      "平均 Accuracy: 0.8836\n",
      "平均迭代次数: 1111.8\n",
      "--------------------------------------------------\n",
      "正在运行实验 - 预处理方法: normalize, 使用 SMOTE: False\n",
      "平均 Precision: 0.8722\n",
      "平均 Recall: 0.8818\n",
      "平均 F1 Score: 0.8651\n",
      "平均 AUC: 0.8266\n",
      "平均 Accuracy: 0.8818\n",
      "平均迭代次数: 42.4\n",
      "--------------------------------------------------\n",
      "正在运行实验 - 预处理方法: log_normalize, 使用 SMOTE: False\n",
      "平均 Precision: 0.8833\n",
      "平均 Recall: 0.8900\n",
      "平均 F1 Score: 0.8771\n",
      "平均 AUC: 0.8319\n",
      "平均 Accuracy: 0.8900\n",
      "平均迭代次数: 42.8\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "###运行结果###\n",
    "\n",
    "# 代码实践\n",
    "cols_continuous1 = ['Age', 'MonthlyIncome', 'NumCompaniesWorked', 'TotalWorkingYears', 'TrainingTimesLastYear', \n",
    "                    'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "\n",
    "# 定义所有实验配置\n",
    "preprocess_methods = ['none', 'normalize', 'log_normalize']\n",
    "use_smote_options = [False]\n",
    "\n",
    "# 不采用任何采样处理\n",
    "for preprocess_method in preprocess_methods:\n",
    "    for use_smote in use_smote_options:\n",
    "        experiment = LogisticRegressionExperiment(\n",
    "            df_drop, \n",
    "            'Attrition', \n",
    "            cols_continuous1, \n",
    "            preprocess_method=preprocess_method, \n",
    "            use_smote=use_smote\n",
    "        )\n",
    "        experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在运行实验 - 预处理方法: none, 使用 SMOTE: True\n",
      "平均 Precision: 0.8537\n",
      "平均 Recall: 0.7855\n",
      "平均 F1 Score: 0.8074\n",
      "平均 AUC: 0.8191\n",
      "平均 Accuracy: 0.7855\n",
      "平均迭代次数: 1282.6\n",
      "--------------------------------------------------\n",
      "正在运行实验 - 预处理方法: normalize, 使用 SMOTE: True\n",
      "平均 Precision: 0.8542\n",
      "平均 Recall: 0.7827\n",
      "平均 F1 Score: 0.8056\n",
      "平均 AUC: 0.8194\n",
      "平均 Accuracy: 0.7827\n",
      "平均迭代次数: 60.0\n",
      "--------------------------------------------------\n",
      "正在运行实验 - 预处理方法: log_normalize, 使用 SMOTE: True\n",
      "平均 Precision: 0.8551\n",
      "平均 Recall: 0.7882\n",
      "平均 F1 Score: 0.8096\n",
      "平均 AUC: 0.8212\n",
      "平均 Accuracy: 0.7882\n",
      "平均迭代次数: 60.6\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 进行SMOTE采样处理\n",
    "use_smote_options = [True]\n",
    "\n",
    "# 遍历所有组合并运行实验\n",
    "for preprocess_method in preprocess_methods:\n",
    "    for use_smote in use_smote_options:\n",
    "        experiment = LogisticRegressionExperiment(\n",
    "            df_drop, \n",
    "            'Attrition', \n",
    "            cols_continuous1, \n",
    "            preprocess_method=preprocess_method, \n",
    "            use_smote=use_smote\n",
    "        )\n",
    "        experiment.run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
